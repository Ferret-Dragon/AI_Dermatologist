{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 3: Knowledge Distillation for AI Dermatologist\n",
    "\n",
    "## CS 4774 Machine Learning - University of Virginia\n",
    "\n",
    "In this notebook, you'll implement knowledge distillation to improve your skin disease classifier by learning from **MedSigLIP** (from Google), a powerful medical imaging model.\n",
    "\n",
    "**Key Requirements:**\n",
    "- Student model must be < **25 MB** on disk\n",
    "- Use MedSigLIP as frozen teacher model (inference only)\n",
    "- Implement temperature-scaled knowledge distillation following Hinton et al. (2015)\n",
    "\n",
    "**Recommended Starting Point:** Use ShuffleNetV2 for your student model (~5 MB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "source": "# =============================\n# CONFIGURATION - Change these values to tune your model\n# =============================\n\n# Dataset Configuration\nDATASET_PATH = 'train_dataset'\nNUM_CLASSES = 10\n\n# Image Processing\nIMAGE_SIZE = 224  # Image dimensions (224x224)\nNORMALIZE_MEAN = [0.485, 0.456, 0.406]  # ImageNet mean\nNORMALIZE_STD = [0.229, 0.224, 0.225]   # ImageNet std\n\n# Training Parameters\nBATCH_SIZE = 32\nNUM_EPOCHS = 10\nLEARNING_RATE = 1e-3\nNUM_WORKERS = 2\n\n# Data Split\nTRAIN_SPLIT = 0.9\nVAL_SPLIT = 0.1\n\n# Knowledge Distillation Parameters\nTEMPERATURE = 4.0   # Temperature for softening distributions\nALPHA = 0.3         # Weight for hard loss (1-alpha for soft loss)\n\n# Model Configuration\nTEACHER_MODEL_NAME = \"google/medsiglip-448\"\nSTUDENT_MODEL_PATH = \"student_model_hw3.pt\"\n\n# Server Configuration\nSERVER_URL = 'http://hadi.cs.virginia.edu:8000'\nMY_TOKEN = 'your_token_here'  # Replace with your actual token\n\nprint(\"Configuration loaded ‚úì\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load Data (Same as HW1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Define dataset class\nclass SkinDataset(Dataset):\n    def __init__(self, root_dir, transform=None):\n        self.root_dir = root_dir\n        self.transform = transform\n        self.classes = sorted([d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))])\n        self.class_to_idx = {cls_name: idx for idx, cls_name in enumerate(self.classes)}\n        self.image_paths = []\n        self.labels = []\n        valid_exts = ('.jpg', '.jpeg', '.png', '.bmp', '.tif', '.tiff', '.jfif')\n        for cls_name in self.classes:\n            cls_dir = os.path.join(root_dir, cls_name)\n            for fname in os.listdir(cls_dir):\n                if fname.lower().endswith(valid_exts):\n                    self.image_paths.append(os.path.join(cls_dir, fname))\n                    self.labels.append(self.class_to_idx[cls_name])\n    def __len__(self):\n        return len(self.image_paths)\n    def __getitem__(self, idx):\n        image = Image.open(self.image_paths[idx]).convert('RGB')\n        label = self.labels[idx]\n        if self.transform:\n            image = self.transform(image)\n        return image, label\n\n# Load data with image size\n# Training transform (Do not change)\ntrain_transform = transforms.Compose([\n    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=NORMALIZE_MEAN, std=NORMALIZE_STD)\n])\n\n# Validation transform (Do not change)\nval_transform = transforms.Compose([\n    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=NORMALIZE_MEAN, std=NORMALIZE_STD)\n])\n\ndataset = SkinDataset(DATASET_PATH, transform=train_transform)\nprint(f'Dataset loaded with {len(dataset)} images and {len(dataset.classes)} classes')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load Teacher Model (MedSigLIP from Google)\n",
    "\n",
    "**Important:** Load the pre-trained MedSigLIP model for inference only. Do NOT fine-tune it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load MedSigLIP teacher model\nfrom transformers import AutoModel, AutoProcessor\n\ndef load_teacher_model():\n    \"\"\"Load MedSigLIP-448 from HuggingFace.\"\"\"\n\n    print(\"Loading MedSigLIP-448 teacher model...\")\n    \n    teacher_model = AutoModel.from_pretrained(TEACHER_MODEL_NAME, trust_remote_code=True)\n    processor = AutoProcessor.from_pretrained(TEACHER_MODEL_NAME, trust_remote_code=True)\n    \n    teacher_model = teacher_model.to(device)\n    teacher_model.eval()\n    \n    # Freeze all parameters\n    for param in teacher_model.parameters():\n        param.requires_grad = False\n    \n    print(\"‚úÖ MedSigLIP loaded successfully!\")\n    return teacher_model, processor\n\n# Load teacher\nteacher_model, teacher_processor = load_teacher_model()\n\n# Define student model: ShuffleNetV2 (Recommended, ~5MB)\nfrom torchvision.models import shufflenet_v2_x0_5\n\ndef create_student_shufflenet(num_classes):\n    \"\"\"Create a ShuffleNetV2 student model (~5 MB).\"\"\"\n    model = shufflenet_v2_x0_5(pretrained=False)\n    # Replace final classifier\n    model.fc = nn.Linear(model.fc.in_features, num_classes)\n    return model\n\n# Create student model\nstudent_model = create_student_shufflenet(num_classes=NUM_CLASSES).to(device)\n\nprint(f'Student model created with {sum(p.numel() for p in student_model.parameters()):,} parameters')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Define Distillation Loss\n",
    "\n",
    "Implement the knowledge distillation loss following Hinton et al. (2015):\n",
    "- **Hard loss**: Cross-entropy with ground truth labels\n",
    "- **Soft loss**: KL divergence between teacher and student soft predictions\n",
    "- **Temperature scaling**: Soften distributions for better knowledge transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "class DistillationLoss(nn.Module):\n    def __init__(self, temperature=4.0, alpha=0.3):\n        super().__init__()\n        self.temperature = temperature\n        self.alpha = alpha\n        # TODO: Initialize cross-entropy loss\n        self.ce_loss = None  #\n    \n    def forward(self, student_logits, teacher_logits, labels):\n        # TODO: Implement hard loss\n        hard_loss = None  # Replace with your implementation\n        \n        # TODO: Implement soft loss \n        # Hint: Use temperature scaling to soften the distributions\n        # Hint: Use F.log_softmax for student and F.softmax for teacher\n        # Hint: Use F.kl_div with reduction='batchmean' and multiply by temperature^2\n        student_soft = None  # Replace with your implementation\n        teacher_soft = None  # Replace with your implementation\n        soft_loss = None  # Replace with your implementation\n        \n        # TODO: Combine hard and soft losses using alpha\n        total_loss = None  # Replace with your implementation\n        \n        return total_loss, hard_loss, soft_loss\n\n# Create an instance of DistillationLoss using config values\ndistillation_loss = DistillationLoss(temperature=TEMPERATURE, alpha=ALPHA)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Train with Knowledge Distillation\n",
    "\n",
    "Implement training loop that:\n",
    "1. Gets teacher's soft predictions (with torch.no_grad())\n",
    "2. Gets student's predictions\n",
    "3. Computes distillation loss\n",
    "4. Updates only student model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Prepare data loaders\ntrain_size = int(TRAIN_SPLIT * len(dataset))\nval_size = len(dataset) - train_size\ntrain_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\nval_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n\n# Setup training\noptimizer = optim.Adam(student_model.parameters(), lr=LEARNING_RATE)\ncriterion = distillation_loss\n\n# Training function\ndef train_epoch(student, teacher, teacher_proc, dataloader, criterion, optimizer):\n    student.train()\n    total_loss = 0\n    \n    for images, labels in tqdm(dataloader, desc='Training'):\n        images, labels = images.to(device), labels.to(device)\n        \n        # Get teacher predictions (no gradients)\n        with torch.no_grad():\n            # TODO: Process images for MedSigLIP and get teacher logits\n            # This requires converting images to PIL format for teacher_processor\n            # For now, using student predictions as placeholder\n            teacher_logits = student(images).detach()  # REPLACE THIS with actual teacher inference\n        \n        # Get student predictions\n        student_logits = student(images)\n        \n        # Compute distillation loss\n        loss, hard_loss, soft_loss = criterion(student_logits, teacher_logits, labels)\n        \n        # Backpropagation\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        total_loss += loss.item()\n    \n    return total_loss / len(dataloader)\n\n# Validation function\ndef validate(student, dataloader):\n    student.eval()\n    all_preds, all_labels = [], []\n    \n    with torch.no_grad():\n        for images, labels in tqdm(dataloader, desc='Validation'):\n            images = images.to(device)\n            outputs = student(images)\n            preds = torch.argmax(outputs, dim=1)\n            \n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels.numpy())\n    \n    accuracy = accuracy_score(all_labels, all_preds)\n    f1 = f1_score(all_labels, all_preds, average='macro')\n    return accuracy, f1\n\n# Training loop\nbest_f1 = 0\n\nfor epoch in range(NUM_EPOCHS):\n    print(f'\\nEpoch {epoch+1}/{NUM_EPOCHS}')\n    \n    # Train\n    train_loss = train_epoch(student_model, teacher_model, teacher_processor, \n                             train_loader, criterion, optimizer)\n    \n    # Validate\n    val_acc, val_f1 = validate(student_model, val_loader)\n    \n    print(f'Train Loss: {train_loss:.4f} | Val Acc: {val_acc:.4f} | Val F1: {val_f1:.4f}')\n    \n    if val_f1 > best_f1:\n        best_f1 = val_f1\n        print(f'‚úÖ New best F1: {best_f1:.4f}')\n\nprint(f'\\nTraining complete! Best F1: {best_f1:.4f}')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Save and Submit\n",
    "\n",
    "Save your student model (< 25 MB) and submit to the HW3 leaderboard.\n",
    "\n",
    "**Important:** Only submit the student model, NOT the teacher!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Save student model\nstudent_model.eval()\nstudent_model.cpu()\nscripted_model = torch.jit.script(student_model)\nscripted_model.save(STUDENT_MODEL_PATH)\n\n# Check model size\nimport os\nsize_mb = os.path.getsize(STUDENT_MODEL_PATH) / (1024 * 1024)\nprint(f'‚úÖ Model saved: {STUDENT_MODEL_PATH}')\nprint(f'üì¶ Model size: {size_mb:.2f} MB')\n\nif size_mb >= 25.0:\n    print('‚ùå WARNING: Model exceeds 25 MB limit!')\nelse:\n    print('‚úÖ Model size is within the 25 MB limit')\n\n# Submit to HW3 leaderboard\ndef submit_model(token, model_path, server_url):\n    \"\"\"Submit model to the HW3 leaderboard.\"\"\"\n    with open(model_path, 'rb') as f:\n        files = {'file': f}\n        data = {'token': token}\n        response = requests.post(f'{server_url}/submit', data=data, files=files)\n        resp_json = response.json()\n        if 'message' in resp_json:\n            print(f\"‚úÖ {resp_json['message']}\")\n        else:\n            print(f\"‚ùå {resp_json.get('error', 'Unknown error')}\")\n\n# Check submission status\ndef check_status(token, server_url):\n    \"\"\"Check your submission status.\"\"\"\n    url = f'{server_url}/submission-status/{token}'\n    response = requests.get(url)\n    \n    if response.status_code == 200:\n        attempts = response.json()\n        for a in attempts:\n            score = f\"{a['score']:.4f}\" if isinstance(a['score'], (float, int)) else \"Pending\"\n            size = f\"{a['model_size']:.2f}\" if isinstance(a['model_size'], (float, int)) else \"N/A\"\n            print(f\"Attempt {a['attempt']}: Score={score}, Size={size} MB, Status={a['status']}\")\n    else:\n        print(f\"Error: {response.status_code}\")\n\n# Uncomment to submit:\n# submit_model(MY_TOKEN, STUDENT_MODEL_PATH, SERVER_URL)\n# check_status(MY_TOKEN, SERVER_URL)\n\nprint(f'\\nüéØ View the HW3 leaderboard at: {SERVER_URL}/leaderboard3')"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local-venv",
   "language": "python",
   "name": "local-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}